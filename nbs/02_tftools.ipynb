{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp tftools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tftools\n",
    "\n",
    "> Functions for use with TensorFlow 2.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References  \n",
    "The functions below are based on the below sources. Please visit attached links for further understanding.:\n",
    "- Chapter 14 – Deep Computer Vision Using Convolutional Neural Networks, Hands-on Machine Learning with Scikit-Learn, Keras and TensorFlow 2nd Edition by Aurélien Geron: [Github link to notebook](https://github.com/ageron/handson-ml2/blob/master/14_deep_computer_vision_with_cnns.ipynb)\n",
    "    - In particular, functions `random_crop` and `central_crop` are used\n",
    "- Tensorflow Documentation by The Tensorflow Authors:\n",
    "    - [Load Images Notebook Github Link](https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/images.ipynb)\n",
    "    - [tf.image API documentation](https://www.tensorflow.org/api_docs/python/tf/image)\n",
    "    - [Transfer learning with a pretrained ConvNet](https://github.com/tensorflow/docs/blob/master/site/en/tutorials/images/transfer_learning.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def random_crop(image):\n",
    "    \"Random crop of image\"\n",
    "    shape = tf.shape(image)\n",
    "    min_dim = tf.reduce_min([shape[0], shape[1]]) * 90 // 100\n",
    "    return tf.image.random_crop(image, [min_dim, min_dim, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def central_crop(image):\n",
    "    \"Center crop of image\"\n",
    "    shape = tf.shape(image)\n",
    "    min_dim = tf.reduce_min([shape[0], shape[1]])\n",
    "    top_crop = (shape[0] - min_dim) // 4\n",
    "    bottom_crop = shape[0] - top_crop\n",
    "    left_crop = (shape[1] - min_dim) // 4\n",
    "    right_crop = shape[1] - left_crop\n",
    "    return image[top_crop:bottom_crop, left_crop:right_crop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def random_flip(image, horiz=True, vert=False):\n",
    "    \"Randomly flips an image horizontally and/or vertically\"\n",
    "    img = image\n",
    "    if horiz: img = tf.image.random_flip_left_right(img)\n",
    "    if vert: img = tf.image.random_flip_up_down(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def random_brightness(image):\n",
    "    \"Randomly adjust brightness of image\"\n",
    "    return tf.image.random_brightness(image, max_delta = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def random_contrast(image):\n",
    "    \"Randomly adjust contrast of image\"\n",
    "    return tf.image.random_contrast(image, 0, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def random_rotate(image):\n",
    "    \"\"\"\n",
    "    Randomly rotates image and angles are in radians.\n",
    "    Requires tensorflow-addons that currently supports MacOS and Linux only.\n",
    "    \"\"\"\n",
    "    import tensorflow as tf\n",
    "    import tensorflow_addons as tfa\n",
    "    delta = tf.random.uniform([], -0.5, 0.5)\n",
    "    return tfa.image.rotate(image, delta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset reading and processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_label(file_path, CLASS_NAMES):\n",
    "    \"Return label of image for tf.data.Dataset\"\n",
    "    parts = tf.strings.split(file_path, os.path.sep)\n",
    "    return parts[-2] == CLASS_NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def train_test_split(files, valid_pct=0.2, seed=None):\n",
    "    \"Reads in list of file Path objects and randomly split into training and validation\"\n",
    "    files = sorted(files)\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    np.random.shuffle(files)\n",
    "    cut = int((1-valid_pct) * len(files))\n",
    "    return files[:cut], files[cut:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def process_img_path(file_path, CLASS_NAMES=None, img_size=224, augments=None, mode=None):\n",
    "    \"\"\"\n",
    "    process image for use with tf.data map function\n",
    "    - get label\n",
    "    - read and decode using tf.image\n",
    "    - expects two augmentation function lists - one for train, the other for valid/test\n",
    "    \"\"\"\n",
    "    label = get_label(file_path,CLASS_NAMES)\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = tf.image.decode_image(img, channels=3, expand_animations=False)\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    if augments is not None:\n",
    "        train_aug, valid_aug = augments\n",
    "        if mode == 'train':\n",
    "            for f in train_aug:\n",
    "                img = f(img)\n",
    "        else:\n",
    "            for f in valid_aug:\n",
    "                img = f(img)\n",
    "        img = tf.clip_by_value(img, 0, 1)\n",
    "    return tf.image.resize(img, [img_size, img_size]), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def process_img_bytes(img_bytes, img_size=224, augments=None):\n",
    "    \"\"\"\n",
    "    Process single image in int-byte form for use with keras model.predict()\n",
    "    - read with in raw file bytes with functions like tf.io.read_file\n",
    "    - decode using tf.image\n",
    "    - supports one augmentation function list, typically for validation\n",
    "    \"\"\"\n",
    "    try:\n",
    "        img = tf.image.decode_image(img_bytes, channels=3, expand_animations=False)\n",
    "        img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "        if augments is not None:\n",
    "            for f in augments:\n",
    "                img = f(img)\n",
    "            img = tf.clip_by_value(img, 0, 1)\n",
    "        img = tf.image.resize(img, [img_size, img_size])\n",
    "    except Exception as e:\n",
    "        print(f'{e}')\n",
    "    return tf.expand_dims(img, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def read_img_dataset(file_paths, CLASS_NAMES=None, shuffle_size=None, img_size=224, batch_size=32, n_parallel=4, augments=None, mode='train'):\n",
    "    \"\"\"\n",
    "    Image dataset reader for tf.data.Dataset\n",
    "    - get files from folder/list of Pathlib objects\n",
    "    - modes of operation: train, valid, test\n",
    "    - cache for all modes using local disk cache with mode as name of cache\n",
    "    - only shuffle if mode=train. shuffle expects a shuffle size\n",
    "    \"\"\"\n",
    "    ds = tf.data.Dataset.list_files(file_paths)\n",
    "    ds = ds.map(partial(process_img_path,\n",
    "                        CLASS_NAMES=CLASS_NAMES,\n",
    "                        img_size=img_size,\n",
    "                        augments=augments,\n",
    "                        mode=mode), num_parallel_calls=n_parallel)\n",
    "    ds = ds.cache(mode)\n",
    "    if mode == 'train':\n",
    "        ds = ds.shuffle(shuffle_size)\n",
    "    ds = ds.repeat()\n",
    "    ds = ds.batch(batch_size)\n",
    "    return ds.prefetch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Read images from folder of Imagenet style\n",
    "Sample:  \n",
    "- data\n",
    "    - train\n",
    "        - class1\n",
    "        - class2\n",
    "    - valid\n",
    "        - class1\n",
    "        - class2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datapath = Path('path/to/data')\n",
    "# train_aug = [rcrop, rflip]\n",
    "# valid_aug = [crop]\n",
    "# aug = (train_aug, valid_aug)\n",
    "# train_ds = read_img_dataset(str(datapath/train/'*/*'), shuffle=1024, img_size=224, batch_size=32, n_parallel=4, augments=aug, mode='train')\n",
    "# valid_ds = read_img_dataset(str(datapath/valid/'*/*'), img_size=224, batch_size=32, n_parallel=4, augments=aug, mode='valid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Read images from folder (or list) and then shuffle split into train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datapath = Path('path/to/data')\n",
    "# all_files = get_all_files(datapath, recurse=True) # read from folder, can be list\n",
    "# train_filepaths, tmp_filepaths = train_test_split(all_files, valid_pct=0.3, seed=42)\n",
    "# valid_filepaths, test_filepaths = train_test_split(tmp_filepaths, valid_pct=0.5, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ds = read_img_dataset([str(x) for x in train_filepaths], shuffle_size=1024, img_size=IMG_SIZE, batch_size=BATCH_SIZE, n_parallel=4, augments=aug, mode='train')\n",
    "# valid_ds = read_img_dataset([str(x) for x in valid_filepaths], img_size=IMG_SIZE, batch_size=BATCH_SIZE, n_parallel=4, augments=aug, mode='valid')\n",
    "# test_ds = read_img_dataset([str(x) for x in test_filepaths], img_size=IMG_SIZE, batch_size=BATCH_SIZE, n_parallel=4, augments=aug, mode='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def show_batch(dataset, CLASS_NAMES):\n",
    "    \"displays batch of 25 images from a batch of tf.data.Dataset\"\n",
    "    image_batch, label_batch = next(iter(dataset))\n",
    "    image_batch = image_batch.numpy()\n",
    "    label_batch = label_batch.numpy()\n",
    "    plt.figure(figsize=(10,10))\n",
    "    for n in range(25):\n",
    "        ax = plt.subplot(5,5,n+1)\n",
    "        plt.imshow(image_batch[n])\n",
    "        plt.title(CLASS_NAMES[label_batch[n]==1][0].title())\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def plot_history(history):\n",
    "    \"\"\"\n",
    "    Plots accuracy and loss for training and validation\n",
    "    Needs history output from model.fit()\n",
    "    \"\"\"\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(acc, label='Training Accuracy')\n",
    "    plt.plot(val_acc, label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.ylim([min(plt.ylim()),1])\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(loss, label='Training Loss')\n",
    "    plt.plot(val_loss, label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.ylabel('Cross Entropy')\n",
    "    plt.ylim([0,1.0])\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Plot history from model.fit using tf.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_imgtools.ipynb.\n",
      "Converted 02_tftools.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
